{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a796b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARC-AGI Task Visualization\n",
    "\n",
    "This notebook visualizes ARC-AGI puzzles from training dataset JSON files. It displays input-output pairs in a clear format to help understand the dataset structure and patterns.\n",
    "\n",
    "## Features:\n",
    "- Load any ARC training JSON file by path\n",
    "- Visualize all training pairs in 2-column format (Input | Output)\n",
    "- Handle variable number of puzzles per file\n",
    "- Compatible with Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for Google Colab\n",
    "!git clone https://github.com/CalebTalley2024/ARC-AGI-2.git\n",
    "%cd ARC-AGI-2\n",
    "\n",
    "!git checkout vedant\n",
    "\n",
    "# Install exact package versions for reproducibility\n",
    "!pip install --quiet \\\n",
    "    numpy==1.24.4 \\\n",
    "    matplotlib==3.7.5 \\\n",
    "    pandas==2.0.3 \\\n",
    "    scipy==1.10.1 \\\n",
    "    scikit-learn==1.3.2 \\\n",
    "    torch==2.2.2 \\\n",
    "    torchvision==0.17.2 \\\n",
    "    torchaudio==2.2.2 \\\n",
    "    transformers==4.46.3 \\\n",
    "    huggingface-hub==0.36.0 \\\n",
    "    seaborn==0.13.2 \\\n",
    "    plotly==6.4.0 \\\n",
    "    tqdm==4.67.1 \\\n",
    "    pyyaml==6.0.3 \\\n",
    "    requests==2.32.4 \\\n",
    "    packaging==25.0 \\\n",
    "    jsonschema==4.23.0 \\\n",
    "    fastjsonschema==2.21.2 \\\n",
    "    jinja2==3.1.6 \\\n",
    "    markupsafe==2.1.5 \\\n",
    "    urllib3==2.2.3 \\\n",
    "    certifi==2025.10.5 \\\n",
    "    charset-normalizer==3.4.4 \\\n",
    "    idna==3.11 \\\n",
    "    python-dateutil==2.9.0.post0 \\\n",
    "    pytz==2025.2 \\\n",
    "    tzdata==2025.2 \\\n",
    "    six==1.17.0 \\\n",
    "    setuptools==75.3.2\n",
    "\n",
    "# Install the package in development mode\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5843122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Color map for visualization (0-9 colors for ARC grids)\n",
    "COLOR_MAP = [\n",
    "    '#000000',  # 0: black\n",
    "    '#0074D9',  # 1: blue\n",
    "    '#FF4136',  # 2: red  \n",
    "    '#2ECC40',  # 3: green\n",
    "    '#FFDC00',  # 4: yellow\n",
    "    '#AAAAAA',  # 5: grey\n",
    "    '#F012BE',  # 6: magenta\n",
    "    '#FF851B',  # 7: orange\n",
    "    '#7FDBFF',  # 8: sky blue\n",
    "    '#870C25'   # 9: brown\n",
    "]\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ea6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_arc_data(txt_file_path):\n",
    "    \"\"\"\n",
    "    Load ARC training or evaluation data from txt file containing task IDs\n",
    "    \n",
    "    Args:\n",
    "        txt_file_path: Path to .txt file containing list of task IDs\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with task_id as keys and task data as values\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the txt file to get task IDs\n",
    "        with open(txt_file_path, 'r') as f:\n",
    "            task_ids = [line.strip() for line in f if line.strip()]\n",
    "        \n",
    "        # Determine the JSON directory based on txt file name\n",
    "        txt_path = Path(txt_file_path)\n",
    "        base_dir = txt_path.parent\n",
    "        \n",
    "        if 'training' in txt_path.name:\n",
    "            json_dir = base_dir / 'training'\n",
    "        elif 'evaluation' in txt_path.name:\n",
    "            json_dir = base_dir / 'evaluation'\n",
    "        else:\n",
    "            print(f\"Unknown data type from file name: {txt_path.name}\")\n",
    "            return None\n",
    "        \n",
    "        if not json_dir.exists():\n",
    "            print(f\"JSON directory not found: {json_dir}\")\n",
    "            return None\n",
    "        \n",
    "        # Load all JSON files for the task IDs\n",
    "        data = {}\n",
    "        loaded_count = 0\n",
    "        missing_files = []\n",
    "        \n",
    "        for task_id in task_ids:\n",
    "            json_file = json_dir / f\"{task_id}.json\"\n",
    "            \n",
    "            if json_file.exists():\n",
    "                try:\n",
    "                    with open(json_file, 'r') as f:\n",
    "                        task_data = json.load(f)\n",
    "                    data[task_id] = task_data\n",
    "                    loaded_count += 1\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error parsing JSON file {json_file}: {e}\")\n",
    "            else:\n",
    "                missing_files.append(task_id)\n",
    "        \n",
    "        print(f\"Loaded {loaded_count} tasks from {txt_file_path}\")\n",
    "        print(f\"JSON files source: {json_dir}\")\n",
    "        \n",
    "        if missing_files:\n",
    "            print(f\"Missing JSON files for {len(missing_files)} task IDs:\")\n",
    "            for task_id in missing_files[:5]:  # Show first 5 missing\n",
    "                print(f\"   {task_id}.json\")\n",
    "            if len(missing_files) > 5:\n",
    "                print(f\"   ... and {len(missing_files) - 5} more\")\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Data file not found: {txt_file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_random_tasks(txt_file_path, num_tasks=3):\n",
    "    \"\"\"\n",
    "    Load random subset of tasks from txt file containing task IDs\n",
    "    \n",
    "    Args:\n",
    "        txt_file_path: Path to .txt file containing list of task IDs\n",
    "        num_tasks: Number of random tasks to load\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with task_id as keys and task data as values\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the txt file to get task IDs\n",
    "        with open(txt_file_path, 'r') as f:\n",
    "            all_task_ids = [line.strip() for line in f if line.strip()]\n",
    "        \n",
    "        # Randomly select subset of task IDs\n",
    "        import random\n",
    "        if len(all_task_ids) <= num_tasks:\n",
    "            selected_task_ids = all_task_ids\n",
    "            print(f\"Selected all {len(all_task_ids)} available tasks\")\n",
    "        else:\n",
    "            selected_task_ids = random.sample(all_task_ids, num_tasks)\n",
    "            print(f\"Randomly selected {num_tasks} tasks from {len(all_task_ids)} available\")\n",
    "        \n",
    "        # Determine the JSON directory based on txt file name\n",
    "        txt_path = Path(txt_file_path)\n",
    "        base_dir = txt_path.parent\n",
    "        \n",
    "        if 'training' in txt_path.name:\n",
    "            json_dir = base_dir / 'training'\n",
    "        elif 'evaluation' in txt_path.name:\n",
    "            json_dir = base_dir / 'evaluation'\n",
    "        else:\n",
    "            print(f\"Unknown data type from file name: {txt_path.name}\")\n",
    "            return None\n",
    "        \n",
    "        if not json_dir.exists():\n",
    "            print(f\"JSON directory not found: {json_dir}\")\n",
    "            return None\n",
    "        \n",
    "        # Load JSON files for selected task IDs\n",
    "        data = {}\n",
    "        loaded_count = 0\n",
    "        missing_files = []\n",
    "        \n",
    "        for task_id in selected_task_ids:\n",
    "            json_file = json_dir / f\"{task_id}.json\"\n",
    "            \n",
    "            if json_file.exists():\n",
    "                try:\n",
    "                    with open(json_file, 'r') as f:\n",
    "                        task_data = json.load(f)\n",
    "                    data[task_id] = task_data\n",
    "                    loaded_count += 1\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error parsing JSON file {json_file}: {e}\")\n",
    "            else:\n",
    "                missing_files.append(task_id)\n",
    "        \n",
    "        print(f\"Successfully loaded {loaded_count} JSON files\")\n",
    "        if missing_files:\n",
    "            print(f\"Missing JSON files: {missing_files}\")\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Data file not found: {txt_file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading random tasks: {e}\")\n",
    "        return None\n",
    "\n",
    "def plot_grid(grid, title=\"\", ax=None):\n",
    "    \"\"\"Plot a single ARC grid with proper colors\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    \n",
    "    grid_array = np.array(grid)\n",
    "    height, width = grid_array.shape\n",
    "    \n",
    "    # Create color mapping\n",
    "    colored_grid = np.zeros((height, width, 3))\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            color_hex = COLOR_MAP[grid_array[i, j]]\n",
    "            # Convert hex to RGB\n",
    "            r = int(color_hex[1:3], 16) / 255.0\n",
    "            g = int(color_hex[3:5], 16) / 255.0\n",
    "            b = int(color_hex[5:7], 16) / 255.0\n",
    "            colored_grid[i, j] = [r, g, b]\n",
    "    \n",
    "    ax.imshow(colored_grid, interpolation='nearest')\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    # Add grid lines\n",
    "    for i in range(height + 1):\n",
    "        ax.axhline(i - 0.5, color='white', linewidth=1)\n",
    "    for j in range(width + 1):\n",
    "        ax.axvline(j - 0.5, color='white', linewidth=1)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "print(\"Data loading functions defined!\")\n",
    "print(\"Usage:\")\n",
    "print(\"  load_arc_data('data/raw/arc/training.txt') - Load all training tasks\")\n",
    "print(\"  load_arc_data('data/raw/arc/evaluation.txt') - Load all evaluation tasks\") \n",
    "print(\"  load_random_tasks('data/raw/arc/training.txt', 10) - Load 10 random training tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4135b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_task_pairs(task_data, task_id, max_pairs=3):\n",
    "    \"\"\"Visualize input/output pairs for a specific task in 2-column format\"\"\"\n",
    "    if task_id not in task_data:\n",
    "        print(f\"Task {task_id} not found in data\")\n",
    "        return\n",
    "    \n",
    "    task = task_data[task_id]\n",
    "    train_pairs = task['train']\n",
    "    test_pairs = task['test']\n",
    "    \n",
    "    num_train = min(len(train_pairs), max_pairs)\n",
    "    num_test = min(len(test_pairs), max_pairs)\n",
    "    total_pairs = num_train + num_test\n",
    "    \n",
    "    if total_pairs == 0:\n",
    "        print(\"No pairs to visualize\")\n",
    "        return\n",
    "    \n",
    "    # Create subplot grid: 2 columns (Input | Output), rows for each pair\n",
    "    fig, axes = plt.subplots(total_pairs, 2, figsize=(12, 4*total_pairs))\n",
    "    \n",
    "    # Handle single row case\n",
    "    if total_pairs == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    # Plot training pairs\n",
    "    for i in range(num_train):\n",
    "        pair = train_pairs[i]\n",
    "        input_grid = pair['input']\n",
    "        output_grid = pair['output']\n",
    "        \n",
    "        plot_grid(input_grid, f\"Train {i+1} - Input\", axes[i, 0])\n",
    "        plot_grid(output_grid, f\"Train {i+1} - Output\", axes[i, 1])\n",
    "    \n",
    "    # Plot test pairs\n",
    "    for i in range(num_test):\n",
    "        pair = test_pairs[i]\n",
    "        input_grid = pair['input']\n",
    "        output_grid = pair['output']\n",
    "        \n",
    "        row_idx = num_train + i\n",
    "        plot_grid(input_grid, f\"Test {i+1} - Input\", axes[row_idx, 0])\n",
    "        plot_grid(output_grid, f\"Test {i+1} - Output\", axes[row_idx, 1])\n",
    "    \n",
    "    plt.suptitle(f\"ARC Task: {task_id}\", fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def browse_tasks(data, start_idx=0, num_tasks=5):\n",
    "    \"\"\"Browse through multiple tasks with their IDs\"\"\"\n",
    "    task_ids = list(data.keys())\n",
    "    end_idx = min(start_idx + num_tasks, len(task_ids))\n",
    "    \n",
    "    print(f\"Showing tasks {start_idx+1} to {end_idx} of {len(task_ids)} total tasks:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i in range(start_idx, end_idx):\n",
    "        task_id = task_ids[i]\n",
    "        task = data[task_id]\n",
    "        num_train = len(task['train'])\n",
    "        num_test = len(task['test'])\n",
    "        print(f\"{i+1:3d}. Task ID: {task_id} | Train: {num_train} | Test: {num_test}\")\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"To visualize a task, use: visualize_task_pairs(data, 'task_id')\")\n",
    "\n",
    "print(\"Task visualization functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def visualize_task_from_data(data, task_id, max_pairs=3):\n",
    "    \"\"\"Visualize input/output pairs for a specific task from loaded data\"\"\"\n",
    "    if not data or task_id not in data:\n",
    "        print(f\"Task {task_id} not found in provided data\")\n",
    "        return\n",
    "    \n",
    "    task = data[task_id]\n",
    "    train_pairs = task['train']\n",
    "    test_pairs = task['test']\n",
    "    \n",
    "    num_train = min(len(train_pairs), max_pairs)\n",
    "    num_test = min(len(test_pairs), max_pairs)\n",
    "    total_pairs = num_train + num_test\n",
    "    \n",
    "    if total_pairs == 0:\n",
    "        print(\"No pairs to visualize\")\n",
    "        return\n",
    "    \n",
    "    # Create subplot grid: 2 columns (Input | Output), rows for each pair\n",
    "    fig, axes = plt.subplots(total_pairs, 2, figsize=(12, 4*total_pairs))\n",
    "    \n",
    "    # Handle single row case\n",
    "    if total_pairs == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    # Plot training pairs\n",
    "    for i in range(num_train):\n",
    "        pair = train_pairs[i]\n",
    "        input_grid = pair['input']\n",
    "        output_grid = pair['output']\n",
    "        \n",
    "        plot_grid(input_grid, f\"Train {i+1} - Input\", axes[i, 0])\n",
    "        plot_grid(output_grid, f\"Train {i+1} - Output\", axes[i, 1])\n",
    "    \n",
    "    # Plot test pairs\n",
    "    for i in range(num_test):\n",
    "        pair = test_pairs[i]\n",
    "        input_grid = pair['input']\n",
    "        output_grid = pair['output']\n",
    "        \n",
    "        row_idx = num_train + i\n",
    "        plot_grid(input_grid, f\"Test {i+1} - Input\", axes[row_idx, 0])\n",
    "        plot_grid(output_grid, f\"Test {i+1} - Output\", axes[row_idx, 1])\n",
    "    \n",
    "    plt.suptitle(f\"ARC Task: {task_id}\", fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_all_tasks_in_data(data, show_all_pairs=True, max_pairs=3):\n",
    "    \"\"\"\n",
    "    Visualize all tasks in the provided data dictionary\n",
    "    \n",
    "    Args:\n",
    "        data: Dictionary of ARC tasks (from load_arc_data or load_random_tasks)\n",
    "        show_all_pairs: If True, shows all pairs; if False, limits pairs per task\n",
    "        max_pairs: Maximum pairs to show per task when show_all_pairs=False\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        print(\"No data provided\")\n",
    "        return\n",
    "    \n",
    "    task_ids = list(data.keys())\n",
    "    print(f\"Visualizing {len(task_ids)} tasks:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for idx, task_id in enumerate(task_ids, 1):\n",
    "        task = data[task_id]\n",
    "        train_pairs = task['train']\n",
    "        test_pairs = task['test']\n",
    "        \n",
    "        print(f\"\\n{idx}. Task ID: {task_id}\")\n",
    "        print(f\"   Training pairs: {len(train_pairs)}\")\n",
    "        print(f\"   Test pairs: {len(test_pairs)}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Calculate total pairs to show\n",
    "        if show_all_pairs:\n",
    "            num_train = len(train_pairs)\n",
    "            num_test = len(test_pairs)\n",
    "        else:\n",
    "            num_train = min(len(train_pairs), max_pairs)\n",
    "            num_test = min(len(test_pairs), max_pairs)\n",
    "        \n",
    "        total_pairs = num_train + num_test\n",
    "        \n",
    "        if total_pairs == 0:\n",
    "            print(\"No pairs to visualize\")\n",
    "            continue\n",
    "        \n",
    "        # Create subplot grid: 2 columns (Input | Output), rows for each pair\n",
    "        fig, axes = plt.subplots(total_pairs, 2, figsize=(12, 4*total_pairs))\n",
    "        \n",
    "        # Handle single row case\n",
    "        if total_pairs == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        row_idx = 0\n",
    "        \n",
    "        # Plot training pairs\n",
    "        for i in range(num_train):\n",
    "            pair = train_pairs[i]\n",
    "            input_grid = pair['input']\n",
    "            output_grid = pair['output']\n",
    "            \n",
    "            plot_grid(input_grid, f\"Train {i+1} - Input\", axes[row_idx, 0])\n",
    "            plot_grid(output_grid, f\"Train {i+1} - Output\", axes[row_idx, 1])\n",
    "            row_idx += 1\n",
    "        \n",
    "        # Plot test pairs\n",
    "        for i in range(num_test):\n",
    "            pair = test_pairs[i]\n",
    "            input_grid = pair['input']\n",
    "            output_grid = pair['output']\n",
    "            \n",
    "            plot_grid(input_grid, f\"Test {i+1} - Input\", axes[row_idx, 0])\n",
    "            plot_grid(output_grid, f\"Test {i+1} - Output\", axes[row_idx, 1])\n",
    "            row_idx += 1\n",
    "        \n",
    "        plt.suptitle(f\"Task {idx}: {task_id}\", fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        if idx < len(task_ids):\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "def quick_random_visualization(txt_file_path, num_tasks=3):\n",
    "    \"\"\"\n",
    "    Quick function to load random tasks and visualize them\n",
    "    \n",
    "    Args:\n",
    "        txt_file_path: Path to txt file containing task IDs\n",
    "        num_tasks: Number of random tasks to load and visualize\n",
    "    \"\"\"\n",
    "    print(f\"Loading {num_tasks} random tasks from {txt_file_path}...\")\n",
    "    random_data = load_random_tasks(txt_file_path, num_tasks)\n",
    "    \n",
    "    if random_data:\n",
    "        print(f\"Visualizing {len(random_data)} randomly selected tasks:\")\n",
    "        visualize_all_tasks_in_data(random_data, show_all_pairs=True)\n",
    "    else:\n",
    "        print(\"Failed to load random tasks\")\n",
    "\n",
    "print(\"Task visualization functions defined!\")\n",
    "print(\"New functions available:\")\n",
    "print(\"  visualize_task_from_data(data, 'task_id', max_pairs=3)\")\n",
    "print(\"  visualize_all_tasks_in_data(data, show_all_pairs=True)\")\n",
    "print(\"  quick_random_visualization('data/raw/arc/training.txt', num_tasks=3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Load all training data\n",
    "# print(\"Loading ALL training data...\")\n",
    "# training_data = load_arc_data('data/raw/arc/training.txt')\n",
    "\n",
    "# if training_data:\n",
    "#     print(f\"Successfully loaded {len(training_data)} training tasks\")\n",
    "    \n",
    "#     # Show some example task IDs and their structure\n",
    "#     sample_task_ids = list(training_data.keys())[:3]\n",
    "#     print(f\"Sample task IDs: {sample_task_ids}\")\n",
    "    \n",
    "#     # Show structure of first task\n",
    "#     if sample_task_ids:\n",
    "#         first_task = training_data[sample_task_ids[0]]\n",
    "#         print(f\"Structure of task '{sample_task_ids[0]}':\")\n",
    "#         print(f\"   Training examples: {len(first_task['train'])}\")\n",
    "#         print(f\"   Test examples: {len(first_task['test'])}\")\n",
    "        \n",
    "#         if first_task['train']:\n",
    "#             example = first_task['train'][0]\n",
    "#             input_grid = example['input']\n",
    "#             output_grid = example['output']\n",
    "#             print(f\"   First training example:\")\n",
    "#             print(f\"     Input size: {len(input_grid)}x{len(input_grid[0])}\")\n",
    "#             print(f\"     Output size: {len(output_grid)}x{len(output_grid[0])}\")\n",
    "# else:\n",
    "#     print(\"Failed to load training data\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Example 2: Load random subset of training data\n",
    "print(\"Loading RANDOM SUBSET of training data...\")\n",
    "random_training_data = load_random_tasks('data/raw/arc/training.txt', num_tasks=3)\n",
    "\n",
    "if random_training_data:\n",
    "    print(f\"Successfully loaded {len(random_training_data)} random training tasks\")\n",
    "    print(f\"Random task IDs: {list(random_training_data.keys())}\")\n",
    "else:\n",
    "    print(\"Failed to load random training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aec58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Examples - Uncomment to use\n",
    "\n",
    "# Option 1: Visualize a specific task from loaded data\n",
    "# if training_data:\n",
    "#     first_task_id = list(training_data.keys())[0]\n",
    "#     visualize_task_from_data(training_data, first_task_id, max_pairs=2)\n",
    "\n",
    "# Option 2: Visualize all tasks in random subset\n",
    "if random_training_data:\n",
    "    visualize_all_tasks_in_data(random_training_data, show_all_pairs=True)\n",
    "\n",
    "# Option 3: Quick random visualization (loads and shows in one step)\n",
    "# quick_random_visualization('data/raw/arc/training.txt', num_tasks=3)\n",
    "\n",
    "# Option 4: Load and visualize random evaluation tasks\n",
    "# random_eval_data = load_random_tasks('data/raw/arc/evaluation.txt', num_tasks=2)\n",
    "# if random_eval_data:\n",
    "#     visualize_all_tasks_in_data(random_eval_data, show_all_pairs=False, max_pairs=2)\n",
    "\n",
    "print(\"Visualization options available:\")\n",
    "print(\"1. visualize_task_from_data(data, 'task_id', max_pairs=N) - specific task from loaded data\")\n",
    "print(\"2. visualize_all_tasks_in_data(data, show_all_pairs=True) - all tasks in data dict\")\n",
    "print(\"3. quick_random_visualization('path/to/file.txt', num_tasks=N) - load and show random tasks\")\n",
    "print(\"4. load_random_tasks('path/to/file.txt', N) - load N random tasks into data dict\")\n",
    "print(\"\\nTo run examples, uncomment the code above and execute the cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a872c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation data for comparison\n",
    "# eval_data = load_arc_data('data/raw/arc/evaluation.txt')\n",
    "\n",
    "# if eval_data:\n",
    "#     print(f\"Successfully loaded {len(eval_data)} evaluation tasks\")\n",
    "    \n",
    "#     # Show some example task IDs\n",
    "#     sample_eval_ids = list(eval_data.keys())[:3]\n",
    "#     print(f\"Sample evaluation task IDs: {sample_eval_ids}\")\n",
    "    \n",
    "#     # Compare with training data\n",
    "#     if training_data:\n",
    "#         print(f\"Dataset Comparison:\")\n",
    "#         print(f\"   Training tasks: {len(training_data)}\")\n",
    "#         print(f\"   Evaluation tasks: {len(eval_data)}\")\n",
    "        \n",
    "#         # Check for any overlap (should be none)\n",
    "#         overlap = set(training_data.keys()) & set(eval_data.keys())\n",
    "#         if overlap:\n",
    "#             print(f\"   Overlap found: {len(overlap)} tasks\")\n",
    "#         else:\n",
    "#             print(f\"   No overlap - clean data split\")\n",
    "# else:\n",
    "#     print(\"Failed to load evaluation data\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Example: Load random evaluation tasks\n",
    "print(\"Loading RANDOM SUBSET of evaluation data...\")\n",
    "random_eval_data = load_random_tasks('data/raw/arc/evaluation.txt', num_tasks=3)\n",
    "\n",
    "if random_eval_data:\n",
    "    print(f\"Successfully loaded {len(random_eval_data)} random evaluation tasks\")\n",
    "    print(f\"Random evaluation task IDs: {list(random_eval_data.keys())}\")\n",
    "else:\n",
    "    print(\"Failed to load random evaluation data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b71be7c",
   "metadata": {},
   "source": [
    "## Quick Start Guide\n",
    "\n",
    "1. **Setup**: Run the first two cells to install dependencies and import libraries\n",
    "2. **Load Data**: Execute the data loading cells to see available tasks\n",
    "3. **Browse**: Use `browse_tasks(data, start_idx=0, num_tasks=10)` to see task IDs\n",
    "4. **Visualize**: Choose from multiple visualization options below\n",
    "5. **Explore**: Try different parameters to understand various puzzle patterns\n",
    "\n",
    "## Visualization Options\n",
    "\n",
    "### Random Task Selection (NEW!)\n",
    "- `visualize_random_sample()`: Quick way to see 3 random tasks from loaded data\n",
    "- `visualize_random_tasks(data, num_tasks=3, show_all_pairs=True)`: Custom random selection\n",
    "\n",
    "### Specific Task Selection\n",
    "- `visualize_task_pairs(data, 'task_id', max_pairs=3)`: Show specific task with limited pairs\n",
    "- `browse_tasks(data, start_idx=0, num_tasks=10)`: List available task IDs\n",
    "\n",
    "## Key Functions\n",
    "\n",
    "- `load_arc_data(path)`: Load training or evaluation data\n",
    "- `browse_tasks(data, start_idx, num_tasks)`: List available tasks with IDs\n",
    "- `visualize_task_pairs(data, task_id, max_pairs)`: Show input/output pairs for specific task\n",
    "- `visualize_random_tasks(data, num_tasks, show_all_pairs)`: Show random tasks with all/limited pairs\n",
    "- `visualize_random_sample()`: Quick random selection from loaded data\n",
    "- `plot_grid(grid, title)`: Plot individual grid with proper colors\n",
    "\n",
    "## Parameters Explained\n",
    "\n",
    "- `max_pairs`: Limits pairs shown per task (for specific task visualization)\n",
    "- `num_tasks`: Number of tasks to display (for browsing or random selection)\n",
    "- `show_all_pairs`: If True, shows ALL pairs in selected tasks; if False, limits to 3 pairs\n",
    "- `start_idx`: Starting position for browsing tasks\n",
    "\n",
    "## Tips\n",
    "\n",
    "- Each task has multiple training pairs and test pairs\n",
    "- Grids use colors 0-9 mapped to distinct colors\n",
    "- Input/Output pairs show the transformation pattern to learn\n",
    "- Random selection helps discover diverse puzzle types\n",
    "- Use `show_all_pairs=False` for large tasks to avoid overwhelming displays"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
